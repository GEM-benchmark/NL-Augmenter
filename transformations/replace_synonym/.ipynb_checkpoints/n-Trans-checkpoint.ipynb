{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185b3782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/naneja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from TestRunner import convert_to_snake_case\n",
    "from transformation import SynonymTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d1d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef1410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syns:  [Synset('interruption.n.02'), Synset('break.n.02'), Synset('fault.n.04'), Synset('rupture.n.02'), Synset('respite.n.02'), Synset('breakage.n.03'), Synset('pause.n.01'), Synset('fracture.n.01'), Synset('break.n.09'), Synset('break.n.10'), Synset('break.n.11'), Synset('break.n.12'), Synset('break.n.13'), Synset('break.n.14'), Synset('open_frame.n.01'), Synset('break.n.16'), Synset('interrupt.v.04'), Synset('break.v.02'), Synset('break.v.03'), Synset('break.v.04'), Synset('break.v.05'), Synset('transgress.v.01'), Synset('break.v.07'), Synset('break.v.08'), Synset('break.v.09'), Synset('break.v.10'), Synset('break_in.v.01'), Synset('break_in.v.06'), Synset('violate.v.01'), Synset('better.v.01'), Synset('unwrap.v.02'), Synset('break.v.16'), Synset('fail.v.04'), Synset('break.v.18'), Synset('break.v.19'), Synset('break.v.20'), Synset('dampen.v.07'), Synset('break.v.22'), Synset('break.v.23'), Synset('break.v.24'), Synset('break.v.25'), Synset('break.v.26'), Synset('break.v.27'), Synset('break.v.28'), Synset('break.v.29'), Synset('break.v.30'), Synset('separate.v.08'), Synset('demote.v.01'), Synset('bankrupt.v.01'), Synset('break.v.34'), Synset('break.v.35'), Synset('collapse.v.01'), Synset('break_dance.v.01'), Synset('break.v.38'), Synset('break.v.39'), Synset('break.v.40'), Synset('break.v.41'), Synset('break.v.42'), Synset('break.v.43'), Synset('break.v.44'), Synset('break.v.45'), Synset('break.v.46'), Synset('pause.v.02'), Synset('break.v.48'), Synset('break.v.49'), Synset('break.v.50'), Synset('break.v.51'), Synset('break.v.52'), Synset('break.v.53'), Synset('crack.v.01'), Synset('break.v.55'), Synset('break.v.56'), Synset('fracture.v.06'), Synset('break.v.58'), Synset('break.v.59')]\n",
      "syns:  ['interruption', 'break', 'fault', 'rupture', 'respite', 'breakage', 'pause', 'fracture', 'break', 'break', 'break', 'break', 'break', 'break', 'open_frame', 'break']\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "# Then, we're going to use the term \"program\" to find synsets like so:\n",
    "\n",
    "def get_syn(word, seed):\n",
    "    random.seed(seed)\n",
    "    if word.endswith('.'): # to check last word of the sentence\n",
    "        dot = True\n",
    "        word = word[:-1]\n",
    "    else:\n",
    "        dot = False\n",
    "        \n",
    "    syns = wordnet.synsets(word.lower())\n",
    "    print('syns: ', syns)\n",
    "    if len(syns) > 0:\n",
    "        form = syns[0].pos()\n",
    "        syns = [syn.lemmas()[0].name() for syn in syns if syn.pos()==form]\n",
    "        print('syns: ', syns)\n",
    "        syn = random.choice(syns)\n",
    "        if dot:\n",
    "            syn = syn + '.'\n",
    "        return syn\n",
    "    else:\n",
    "        if dot:\n",
    "            return word + '.'\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    return syn\n",
    "\n",
    "word = \"break\"\n",
    "\n",
    "syn = get_syn(word, 0)\n",
    "print(syn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c4ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ad3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = SynonymTransformation(max_outputs=3)\n",
    "sentence = \"All the persons we work with are incredibly awesome.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d7105f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bank report bumper second-quarter profit.',\n",
       " 'depository_financial_institution report bumper second-quarter winnings.',\n",
       " 'Banks reputation bumper second-quarter net_income.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.generate(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d75eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert False\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fedc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded2b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ababe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences =  [\n",
    "    \"All the persons we work with are incredibly awesome.\",\n",
    "    \"Thailand has imposed a nationwide ban on public gatherings.\",\n",
    "    \"The chances of reversing this situation are becoming more distant by the day.\",\n",
    "    \"Your speech was awesome today.\",\n",
    "    \"Banks report bumper second-quarter profits.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79914462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json(sentences):\n",
    "    test_cases = []\n",
    "    for sentence in sentences:\n",
    "        outputs = [{\"sentence\": o} for o in tf.generate(sentence)]\n",
    "        test_cases.append(\n",
    "            {\n",
    "            \"class\": tf.name(),\n",
    "            \"inputs\": {\"sentence\": sentence}, \n",
    "                \"outputs\": outputs}\n",
    "        )\n",
    "    json_file = {\"type\": convert_to_snake_case(tf.name()), \"test_cases\": test_cases}\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf340616",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = generate_json(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e84ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json', 'w') as fp:\n",
    "    json.dump(json_file, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47e24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"synonym_transformation\",\n",
      "  \"test_cases\": [\n",
      "    {\n",
      "      \"class\": \"SynonymTransformation\",\n",
      "      \"inputs\": {\n",
      "        \"sentence\": \"All the persons we work with are incredibly awesome.\"\n",
      "      },\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"sentence\": \"All the person we work with are fabulously awesome.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"All the persons we work with are incredibly amazing.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"All the person we work with are incredibly awesome.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"class\": \"SynonymTransformation\",\n",
      "      \"inputs\": {\n",
      "        \"sentence\": \"Thailand has imposed a nationwide ban on public gatherings.\"\n",
      "      },\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"sentence\": \"Thailand has inflict a countrywide ban on public gatherings.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"Thailand has imposed a countrywide ban on populace assembly.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"Thailand has enforce a countrywide ban on populace gathering.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"class\": \"SynonymTransformation\",\n",
      "      \"inputs\": {\n",
      "        \"sentence\": \"The chances of reversing this situation are becoming more distant by the day.\"\n",
      "      },\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"sentence\": \"The chances of revoke this site are become more distant by the day.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"The luck of reversing this situation are becoming more distant by the day.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"The opportunity of change_by_reversal this situation are become more distant by the day.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"class\": \"SynonymTransformation\",\n",
      "      \"inputs\": {\n",
      "        \"sentence\": \"Your speech was awesome today.\"\n",
      "      },\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"sentence\": \"Your speech was amazing today.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"Your speech was awesome today.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"Your address was amazing today.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"class\": \"SynonymTransformation\",\n",
      "      \"inputs\": {\n",
      "        \"sentence\": \"Banks report bumper second-quarter profits.\"\n",
      "      },\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"sentence\": \"bank report bumper second-quarter profit.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"depository_financial_institution report bumper second-quarter winnings.\"\n",
      "        },\n",
      "        {\n",
      "          \"sentence\": \"Banks reputation bumper second-quarter net_income.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_file, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
