{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL-Augmenter  ü¶é ‚Üí üêç Write a sample transformation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ebe94b3466943ddba5b8ab874daf900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a905fb867c8a44338d5f35f38a19b46e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14bb03f053f64a278e3968840eb959fd",
              "IPY_MODEL_0f6a1bf4be7b42fd9c0c3929fd478e3b"
            ]
          }
        },
        "a905fb867c8a44338d5f35f38a19b46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14bb03f053f64a278e3968840eb959fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_962f4cd8298940368632450846bca967",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891737400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891737400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90f2d6ac1f17408a9408d6c316a1e29e"
          }
        },
        "0f6a1bf4be7b42fd9c0c3929fd478e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4958a0e991d049339723fe494f573229",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:21&lt;00:00, 42.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8933b6543ead40fb826e135d82f5982c"
          }
        },
        "962f4cd8298940368632450846bca967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90f2d6ac1f17408a9408d6c316a1e29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4958a0e991d049339723fe494f573229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8933b6543ead40fb826e135d82f5982c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drfP193NQSZ6"
      },
      "source": [
        "<a href =\"https://colab.research.google.com/github/GEM-benchmark/NL-Augmenter/blob/main/notebooks/NL_Augmenter_Write_a_sample_transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMrWwwGdP4wO"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_4yHCIAvQx"
      },
      "source": [
        "## Install NL-Augmenter from GitHub\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkv4WSJsI7YV"
      },
      "source": [
        "!git clone https://www.github.com/GEM-benchmark/NL-Augmenter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9KCH1qpHjDo"
      },
      "source": [
        "cd NL-Augmenter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMiID0kSE_Qf"
      },
      "source": [
        "!pip install -r requirements.txt --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJcZGbR7JVFt"
      },
      "source": [
        "from transformations.butter_fingers_perturbation.transformation import ButterFingersPerturbation\n",
        "from transformations.change_person_named_entities.transformation import ChangePersonNamedEntities\n",
        "from transformations.replace_numerical_values.transformation import ReplaceNumericalValues\n",
        "from interfaces.SentenceOperation import SentenceOperation\n",
        "from interfaces.QuestionAnswerOperation import QuestionAnswerOperation\n",
        "from evaluation.evaluation_engine import evaluate, execute_model\n",
        "from tasks.TaskTypes import TaskType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT8V407QBFYz"
      },
      "source": [
        "## Play with some existing transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MZfjp0toJdHh",
        "outputId": "4c26c18f-3bf9-42ad-f588-81788c714cba"
      },
      "source": [
        "t1 = ButterFingersPerturbation()\n",
        "t1.generate(\"Jason wants to move back to India by the end of next year.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perturbed Input from ButterFingersPerturbation : Jasln wants to move back to India by the end od next year.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jasln wants to move back to India by the end od next year.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "S_o9ktK9JwKs",
        "outputId": "cf70bae3-eca5-4da3-c8d1-5aeab526f270"
      },
      "source": [
        "t2 = ChangePersonNamedEntities()\n",
        "t2.generate(\"Jason wants to move back to India by the end of next year.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perturbed Input from ChangePersonNamedEntities : Austin wants to move back to India by the end of next year.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Austin wants to move back to India by the end of next year.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "v1khspY1AH_j",
        "outputId": "a0cdd73b-0aaf-4d07-b16c-89b39d1e3321"
      },
      "source": [
        "t3 = ReplaceNumericalValues()\n",
        "t3.generate(\"Jason's 3 sisters want to move back to India\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perturbed Input from ReplaceNumericalValues : Jason's 6 sisters want to move back to India\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Jason's 6 sisters want to move back to India\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2CB0LRbBWST"
      },
      "source": [
        "## Define a simple transformation\n",
        "Let's define a very basic transformation which just uppercases the sentence. \n",
        "\n",
        "This transformation could be used for many [tasks](https://github.com/GEM-benchmark/NL-Augmenter/blob/add_filters_for_contrast_sets/tasks/TaskTypes.py) including text classification and generation. So, we need to populate the `tasks` variable to `[TaskType.TEXT_CLASSIFICATION, TaskType.TEXT_TO_TEXT_GENERATION]`. That's it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BymdwQ3PJzg7"
      },
      "source": [
        "class MySimpleTransformation(SentenceOperation):\n",
        "  tasks = [TaskType.TEXT_CLASSIFICATION, TaskType.TEXT_TO_TEXT_GENERATION]\n",
        "  locales = [\"en\"]\n",
        "  \n",
        "  def generate(self, sentence):\n",
        "    return sentence.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkqtwqYlUWXV"
      },
      "source": [
        "my_transformation = MySimpleTransformation() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rbbSJxJ8UbVz",
        "outputId": "1beb8dd3-68d0-4683-a391-167c7b91d94f"
      },
      "source": [
        "my_transformation.generate(\"John was n't the person I had n't imagined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"JOHN WAS N'T THE PERSON I HAD N'T IMAGINED.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8682Ql9GOP0"
      },
      "source": [
        "\n",
        "Obviously this can barely be called a transformation. What could this really achieve? Duh. \n",
        "So, let's quickly compare the performance of a trained text classifier on a common test set, and a test set with MySimpleTransformation applied (or also called as a pertubed set) with this one line of code. And you need to hold your breadth for around 5 minutes!  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJlW0WnrVU0n"
      },
      "source": [
        "execute_model(MySimpleTransformation, \"TEXT_CLASSIFICATION\", percentage_of_examples=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_NeVxa0RKWx"
      },
      "source": [
        "### üï∫ Voila! The accuracy on the perturbed set has fallen by 6% with this simple transformation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4qmvF6sQRWu"
      },
      "source": [
        "So what happened internally? --> `execute_model` depending on the transformation type [SentenceOperation](https://github.com/GEM-benchmark/NL-Augmenter/blob/main/interfaces/SentenceOperation.py)) and the task you provided (TEXT_CLASSIFICATION) evaluated a pre-trained model of HuggingFace. In this case, a sentiment analysis model [aychang/roberta-base-imdb](https://huggingface.co/aychang/roberta-base-imdb) was chosen and evaluated on 1% of the [IMDB dataset](https://huggingface.co/datasets/imdb) with and without the transformation to check if the sentiment is predicted correctly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmOP8B3-TW0i"
      },
      "source": [
        "If you want to evaluate this on your own model and dataset, you can pass the parameters as shown below in the `execute_model` method. Note that we obviously can't support each and every model type and dataset type and hence some models and datasets might require refactoring in the `evaluation_engine` class from your side and we are happy to help. üòä"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKcUmvYzYKAJ"
      },
      "source": [
        "# execute_model(MySimpleTransformation, \"TEXT_CLASSIFICATION\", \"en\", model_name = \"aychang/roberta-base-imdb\", dataset=\"imdb\", percentage_of_examples=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHuYXB6OWNiU"
      },
      "source": [
        "##  A Model Based Transformation\n",
        "We don't want to restrict ourselves with just string level changes! We want to do more, don't we? So, let's use a pre-trained paraphrase generator to transform question answering examples. There is an exisiting interface [QuestionAnswerOperation](https://github.com/GEM-benchmark/NL-Augmenter/blob/main/interfaces/QuestionAnswerOperation.py) which takes as input the context, the question and the answer as inputs. Let's use that to augment our training data for question answering! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3DehjWXYwnn"
      },
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "\n",
        "class MySecondTransformation(QuestionAnswerOperation):\n",
        "  tasks = [TaskType.QUESTION_ANSWERING, TaskType.QUESTION_GENERATION]\n",
        "  locales = [\"en\"]\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    model_name=\"prithivida/parrot_paraphraser_on_T5\"\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)  \n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "  def generate(self, context, question, answers): # Note that the choice of inputs for 'generate' is consistent with those in QuestionAnswerOperation\n",
        "    \n",
        "    # Let's call the HF model to generate a paraphrase for the question\n",
        "    paraphrase_input = question\n",
        "    batch = self.tokenizer([paraphrase_input],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\")\n",
        "    translated = self.model.generate(**batch,max_length=60,num_beams=10, num_return_sequences=1, temperature=1.5)\n",
        "    paraphrased_question = self.tokenizer.batch_decode(translated, skip_special_tokens=True) \n",
        "\n",
        "    # context = \"Apply your own logic here\"\n",
        "    # answers = \"And here too :)\"\n",
        "\n",
        "    # return the new question-answering example\n",
        "    return context, paraphrased_question, answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84G9YzdGblfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ebe94b3466943ddba5b8ab874daf900",
            "a905fb867c8a44338d5f35f38a19b46e",
            "14bb03f053f64a278e3968840eb959fd",
            "0f6a1bf4be7b42fd9c0c3929fd478e3b",
            "962f4cd8298940368632450846bca967",
            "90f2d6ac1f17408a9408d6c316a1e29e",
            "4958a0e991d049339723fe494f573229",
            "8933b6543ead40fb826e135d82f5982c"
          ]
        },
        "outputId": "990d75ce-e75d-4a65-baff-9400b6a38955"
      },
      "source": [
        "t4 = MySecondTransformation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ebe94b3466943ddba5b8ab874daf900",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891737400.0, style=ProgressStyle(descri‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFY0lGA2lIqy",
        "outputId": "24b002be-c91a-4768-c24e-e16d54b24fb8"
      },
      "source": [
        "t4.generate(context=\"Mumbai, Bengaluru, New Delhi are among the many famous places in India.\", \n",
        "            question=\"What are the famous places we should not miss in India?\", \n",
        "            answers=[\"Mumbai\", \"Bengaluru\", \"Delhi\", \"New Delhi\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Mumbai, Bengaluru, New Delhi are among the many famous places in India.',\n",
              " ['recommend some of the best places to visit in India?'],\n",
              " ['Mumbai', 'Bengaluru', 'Delhi', 'New Delhi'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOCoNfaV6F9l"
      },
      "source": [
        "Voila! Seems like you have created a new training example now for question-answering and question-generation! üéâ üéä üéâ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WF-JtPd6wAm"
      },
      "source": [
        "Now you are all ready to contribute a transformation to [NL-Augmenter ü¶é ‚Üí üêç](https://github.com/GEM-benchmark/NL-Augmenter)!"
      ]
    }
  ]
}